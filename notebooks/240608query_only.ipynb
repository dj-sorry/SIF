{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sif_src.utils import load_glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_pickle(\"../pickle_backups/marco_valid_df2024-06-04T17.38.1717490321.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_passages = valid_df[\"passages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_texts = []\n",
    "for i in range(len(valid_passages)):\n",
    "    valid_texts.append(valid_passages[i][\"passage_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df[\"texts\"] = valid_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors, word_to_index = load_glove_vectors('../wv/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "\n",
    "for inner_list in valid_df['texts']:\n",
    "    for sentence in inner_list:\n",
    "        word_counts.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sif_weight(word, a=1e-3):\n",
    "    return a / (a + word_counts[word])\n",
    "\n",
    "def sentence_to_sif(sentence, embeddings_index, embedding_dim=50, a=1e-3):\n",
    "    words = sentence.split()\n",
    "    weights = [sif_weight(word) for word in words]\n",
    "    embedding_matrix = np.zeros((len(words), embedding_dim))\n",
    "    for i, word in enumerate(words):\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector * weights[i]\n",
    "    return np.sum(embedding_matrix, axis=0) / (np.sum(weights) + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_embeddings(passage, word_to_index, embeddings_index, embedding_dim=50):\n",
    "    words = passage.split()\n",
    "    embedding_matrix = np.zeros((len(words), embedding_dim))\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        word_index = word_to_index.get(word.lower()) \n",
    "        if word_index is not None:\n",
    "            embedding_vector = embeddings_index[word_index]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    if len(words) > 0:\n",
    "        return np.mean(embedding_matrix, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_call_count = 0\n",
    "\n",
    "def compute_passage_embeddings(passage_texts, embedding_type, word_to_index, glove_vectors):\n",
    "    global apply_call_count\n",
    "    passage_embeddings = []\n",
    "    total_iterations = 0\n",
    "    \n",
    "    for text in passage_texts:\n",
    "        sentence_embeddings = []\n",
    "        for sentence in text:\n",
    "            if embedding_type == 'sif':\n",
    "                embedding = sentence_to_sif(sentence, glove_vectors)\n",
    "            elif embedding_type == 'glove':\n",
    "                embedding = glove_embeddings(sentence, word_to_index, glove_vectors)\n",
    "            sentence_embeddings.append(embedding)\n",
    "        passage_embeddings.append(sentence_embeddings)\n",
    "        total_iterations += 1\n",
    "        print(\"Iterations processed in compute_passage_embeddings:\", total_iterations)\n",
    "    \n",
    "    apply_call_count += 1\n",
    "    \n",
    "    return passage_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['query_sif'] = valid_df['query'].apply(lambda x: sentence_to_sif(x, glove_vectors))\n",
    "print(\"Step 1 finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['passage_sif'] = valid_df['texts'].apply(compute_passage_embeddings, args=('sif', word_to_index, glove_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['query_glove'] = valid_df['query'].apply(lambda x: glove_embeddings(x, word_to_index, glove_vectors))\n",
    "print(\"Step 3 finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['passage_glove'] = valid_df['texts'].apply(compute_passage_embeddings, args=('glove', word_to_index, glove_vectors))\n",
    "print(\"Step 4 finished\")\n",
    "\n",
    "print(\"Total number of times apply is called:\", apply_call_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle_backups/0608_valid_sifglove.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
